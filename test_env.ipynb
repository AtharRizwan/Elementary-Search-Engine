{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\athar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\athar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\athar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import json\n",
    "import re\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "import validators\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")\n",
    "nltk.download('stopwords')\n",
    "# Initialize Word_Net_Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_json(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "barrels = []\n",
    "barrel_size = 1000\n",
    "barrel_files = os.listdir(r\"Files\\Barrels\")\n",
    "# Load all barrels that currently exist\n",
    "for barrel in barrel_files:\n",
    "    barrels.append(load_data_from_json(os.path.join(r\"Files\\Barrels\", barrel)))\n",
    "# Load lexicon\n",
    "lexicon = load_data_from_json(r\"Files\\lexicon.json\")\n",
    "# Load the documents\n",
    "documents = load_data_from_json(r\"Files\\documents.json\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that takes in content, preprocesses it, \n",
    "# and converts it to a list of words\n",
    "def pre_process_string(content):\n",
    "    # Remove \\n and \\t\n",
    "    content = content.replace('\\n', ' ')\n",
    "    content = content.replace('\\t', ' ')\n",
    "    # Remove all non-characters\n",
    "    content = re.sub(r'[^a-zA-Z\\s]', ' ', content)\n",
    "    # Remove multiple spaces\n",
    "    content = re.sub(r'\\s+', ' ', content)\n",
    "    # Convert all characters to lowercase\n",
    "    content = content.lower()\n",
    "    # Convert the title into a list of words\n",
    "    content = content.split()\n",
    "    # Remove one and two character words\n",
    "    content = [word for word in content if len(word) > 2]\n",
    "    # Remove stop_words using nltk\n",
    "    content = [word for word in content if not word in stopwords.words('english')]\n",
    "    return content\n",
    "    \n",
    "# Function that takes in a list of words and adds them to the lexicon\n",
    "def build_lexicon(words):\n",
    "    # Build the lexicon\n",
    "    new_words = []\n",
    "    # Look through the words\n",
    "    for word in words:\n",
    "        # Lemmatize the word\n",
    "        word = lemmatizer.lemmatize(word)\n",
    "        # if that word is not already in lexicon\n",
    "        if word not in lexicon and word not in new_words:\n",
    "            # Then add it\n",
    "            new_words.append(word)\n",
    "    lexicon.extend(new_words)\n",
    "    return\n",
    "\n",
    "# Function to build forward index from raw articles\n",
    "def build_forward_index(articles):\n",
    "\n",
    "    # initialize forward_index\n",
    "    forward_index = dict()\n",
    "\n",
    "    #initialize documents\n",
    "    docs = dict()\n",
    "\n",
    "    # Load the already existing forward_index\n",
    "    try:\n",
    "        data = load_data_from_json(r\"Files\\forward_index.json\")\n",
    "    except:\n",
    "        with open(r\"Files\\forward_index.json\", \"w\") as file:\n",
    "            json.dump(dict(), file)\n",
    "        data = load_data_from_json(r\"Files\\forward_index.json\")\n",
    "        \n",
    "    num_articles = len(documents)\n",
    "    \n",
    "    # Extract all urls currently indexed\n",
    "    try:\n",
    "        article_urls = [article['url'] for article in documents.values()]\n",
    "    except:\n",
    "        article_urls = []\n",
    "        \n",
    "    # For each article\n",
    "    for article in articles:\n",
    "        # if article is not already forward indexed\n",
    "        if article['url'] not in article_urls:\n",
    "            # Pre-process the title and content\n",
    "            title_words = pre_process_string(article['title'])\n",
    "            content_words = pre_process_string(article['content'])\n",
    "            # Update the lexicon\n",
    "            build_lexicon(title_words + content_words)\n",
    "            # Lemmatize the words in content and title\n",
    "            content_words = [lemmatizer.lemmatize(word) for word in content_words]\n",
    "            title_words = [lemmatizer.lemmatize(word) for word in title_words]\n",
    "            # Convert the words in title and content to their respective indexes\n",
    "            content_ids = [lexicon.index(word) for word in content_words]\n",
    "            title_ids = [lexicon.index(word) for word in title_words]\n",
    "            # Count the frequencies of words\n",
    "            frequency = Counter((title_ids * 10) + content_ids)\n",
    "            forward_index[num_articles] = frequency\n",
    "            docs[str(num_articles)] = {'title': article['title'], 'url': article['url']}\n",
    "            # Add the url to the article\n",
    "            article_urls.append(article['url'])\n",
    "            num_articles += 1\n",
    "    data.update(forward_index)\n",
    "    print(docs)\n",
    "    documents.update(docs)\n",
    "    # Update the lexicon json file\n",
    "    # with open(r\"Files\\lexicon.json\", \"w\") as file:\n",
    "    #     json.dump(lexicon, file)\n",
    "    # Update the forward_index json file\n",
    "    with open(r\"Files\\forward_index.json\", \"w\") as file:\n",
    "        json.dump(data, file)\n",
    "    # Update the documents json file\n",
    "    # with open(r\"Files\\documents.json\", \"w\") as file:\n",
    "    #     json.dump(documents, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.23 s\n",
      "Wall time: 1.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "build_forward_index(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Barrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_inverted_index_with_barrels():\n",
    "\n",
    "    # Load the forward index\n",
    "    try:\n",
    "        forward_index = load_data_from_json(r\"Files\\forward_index.json\")\n",
    "    except:\n",
    "        return\n",
    "\n",
    "    # Iterate through all articles in the forward_index\n",
    "    for doc_id, data in forward_index.items():\n",
    "        # Look at all words in an article\n",
    "        for word_id in data:\n",
    "            # Calculate the barrel number for that word\n",
    "            barrel_no = int(word_id) // barrel_size\n",
    "            barrel_filename = f\"barrel_{str(barrel_no).zfill(5)}.json\"\n",
    "            \n",
    "            # Check if that barrel exists, if not then create it\n",
    "            barrel_path = os.path.join(r\"Files\\Barrels\", barrel_filename)\n",
    "            if not os.path.exists(barrel_path):\n",
    "                with open(barrel_path, \"w\") as file:\n",
    "                    json.dump(dict(), file)\n",
    "                # Load the newly created barrel\n",
    "                barrels.append(load_data_from_json(barrel_path))\n",
    "                barrel_files.append(barrel_filename)\n",
    "            # update the word_id\n",
    "            word_id_new = str(int(word_id) % barrel_size)\n",
    "            # If that word is not already in that barrel\n",
    "            if word_id_new not in barrels[barrel_no]:\n",
    "                # Then create a dict at that word_id\n",
    "                barrels[barrel_no][word_id_new] = dict()\n",
    "            # And add the doc_id for that word along with frequency if it is not already there\n",
    "            if doc_id not in barrels[barrel_no][word_id_new]:\n",
    "                barrels[barrel_no][word_id_new].update({doc_id: data[word_id]})\n",
    "\n",
    "    # # Update all barrels\n",
    "    # for i, barrel in enumerate(barrel_files):\n",
    "    #     with open(os.path.join(r\"Files\\Barrels\", barrel), \"w\") as file:\n",
    "    #         json.dump(barrels[i], file)\n",
    "    \n",
    "    # Clear the forward_index\n",
    "    with open(r\"Files\\forward_index.json\", \"w\") as file:\n",
    "        json.dump(dict(), file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 55.9 s\n",
      "Wall time: 56.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "build_inverted_index_with_barrels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing out Single and Multi-Word Search on stored forward and reverse index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_results(search_result): \n",
    "     # Rank these documents\n",
    "    # Sort the dictionary by values (descending order)\n",
    "    sorted_tuples = sorted(search_result.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Convert the sorted list of tuples back to a dictionary\n",
    "    ranked_result = dict(sorted_tuples)\n",
    "    # Extract the article ids\n",
    "    ranked_articles = ranked_result.keys()\n",
    "    ranked_articles = list(ranked_articles)\n",
    "    \n",
    "\n",
    "    return ranked_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for single word queries\n",
    "def single_word_search(word):\n",
    "    # Lemmatize the word\n",
    "    word = lemmatizer.lemmatize(word)\n",
    "        \n",
    "    # Find the id of the word in lexicon\n",
    "    try:\n",
    "        word_id = lexicon.index(word)\n",
    "        # Calculate the barrel of the word\n",
    "        barrel_no = word_id // barrel_size\n",
    "        # Update the word_id\n",
    "        word_id = word_id % barrel_size\n",
    "        # Find out in which documents does the word appear\n",
    "        search_result = barrels[barrel_no][str(word_id)]\n",
    "    except:\n",
    "        search_result = None\n",
    "    \n",
    "    if search_result is None: \n",
    "        return []\n",
    "\n",
    "    article_ids = rank_results(search_result)\n",
    "    titles = [documents[article]['title'] for article in article_ids]\n",
    "    urls = [documents[article]['url'] for article in article_ids]\n",
    "\n",
    "    return titles\n",
    "\n",
    "# Function for multi-word queries\n",
    "def multi_word_search(query): \n",
    "    result = []\n",
    "\n",
    "    # Preprocess the query\n",
    "    words = pre_process_string(query)\n",
    "\n",
    "    # Remove those words that are not in lexicon\n",
    "    words = [word for word in words if word in lexicon]\n",
    "    # Convert each word to its word_id\n",
    "    word_ids = [lexicon.index(word) for word in words]\n",
    "    # Calculate barrel_no of each word and its index in that barrel\n",
    "    barrel_nos = [word_id // barrel_size for word_id in word_ids]\n",
    "    word_ids = [word_id % barrel_size for word_id in word_ids]\n",
    "\n",
    "    # Check the first word\n",
    "    if word_ids:\n",
    "        result = loaded_barrels[barrel_nos[0]][str(word_ids[0])]\n",
    "        # Check the rest of the words\n",
    "        for i, word_id in enumerate(word_ids[1:], start = 1):\n",
    "            # Produce the result for current word\n",
    "            current_result = loaded_barrels[barrel_nos[i]][str(word_id)]\n",
    "            # Include those articles that are also in the result of current word\n",
    "            result.update({d:result[d]+current_result[d] for d in result.keys() if d in current_result.keys()})\n",
    "\n",
    "    if result is None:\n",
    "        return []\n",
    "    \n",
    "    # rank the results\n",
    "    result = rank_results(result)\n",
    "\n",
    "    article_ids = result\n",
    "    titles = [documents[article]['title'] for article in article_ids]\n",
    "    urls = [documents[article]['url'] for article in article_ids]\n",
    "                \n",
    "    return titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Writing your first Django app',\n",
       " \"Kanye West Says 'Django Unchained' Was a Music Video Concept He Pitched to Jamie Foxx & Quentin Tarantino\",\n",
       " '11 Movies Based on True Stories That Were Slightly Changed for Dramatic Purposes',\n",
       " 'Samuel L. Jackson Slams Joe Rogan over N-Word But Defends Pal Quentin Tarantino',\n",
       " 'Israel’s farcical elections and fictional democracy',\n",
       " '8 Celebrities Who Became Famous After 50 and Proved It’s Never Too Late to Follow Your Dreams',\n",
       " '8 Times Actors Broke the Rules Their Studio Set',\n",
       " '14 Super Dedicated Actors Whose Hard Work Left Us Breathless',\n",
       " \"Samuel L. Jackson Blasts the Oscars: Black Actors Usually 'Win for Doing Despicable S**t on Screen'\",\n",
       " 'Harvey Weinstein Goes on Trial in L.A., Where He Once Reigned',\n",
       " 'Who Were The REAL Cowboys?',\n",
       " '\"Fight Club\" has a very different ending in China',\n",
       " 'Fred Ward, acclaimed film and television actor, has died at 79',\n",
       " \"Harvey Weinstein's Los Angeles sexual assault trial set to begin\",\n",
       " \"The Clause aim to be 'the biggest band in Brum' to see where it takes them\"]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_word_search(\"django\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Add Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_content(file, url, title, content):\n",
    "\n",
    "    # Check if a file is uploaded\n",
    "    if file:\n",
    "        # Load the file\n",
    "        data = load_data_from_json(file)\n",
    "    else:\n",
    "        # Check if the url, title and content are correct\n",
    "        if url and title and content:\n",
    "            # Validate the url\n",
    "            if not validators.url(url):\n",
    "                print(\"Please provide a valid url\")\n",
    "                return\n",
    "            # Load the data\n",
    "            data = [{\"title\": title, \"content\": content, \"url\": url}]\n",
    "        else:\n",
    "            print(\"Please provide a file or url, title, and content\")\n",
    "            return\n",
    "\n",
    "    # Build forward and inverted index on it\n",
    "    try:\n",
    "        build_forward_index(data)\n",
    "    except:\n",
    "        print(\"Error building forward index\")\n",
    "        return\n",
    "    build_inverted_index_with_barrels()\n",
    "    \n",
    "    print(\"Successfully added content\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'158506': {'title': 'Writing your first Django app', 'url': 'https://docs.djangoproject.com/en/4.2/intro/tutorial01/'}}\n",
      "Successfully added content\n"
     ]
    }
   ],
   "source": [
    "add_content(None, \"https://docs.djangoproject.com/en/4.2/intro/tutorial01/\", \"Writing your first Django app\", \"This tutorial is written for Django 4.2, which supports Python 3.8 and later. If the Django version doesn’t match, you can refer to the tutorial for your version of Django by using the version switcher at the bottom right corner of this page, or update Django to the newest version. If you’re using an older version of Python, check What Python version can I use with Django? to find a compatible version of Django.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://docs.djangoproject.com/en/4.2/intro/tutorial01/\"\n",
    "title =  \"Writing your first Django app\"\n",
    "content = \"This tutorial is written for Django 4.2, which supports Python 3.8 and later. If the Django version doesn’t match, you can refer to the tutorial for your version of Django by using the version switcher at the bottom right corner of this page, or update Django to the newest version. If you’re using an older version of Python, check What Python version can I use with Django? to find a compatible version of Django.\"\n",
    "data = [{\"title\":title, \"content\":content, \"url\":url}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Writing your first Django app',\n",
       "  'content': 'This tutorial is written for Django 4.2, which supports Python 3.8 and later. If the Django version doesn’t match, you can refer to the tutorial for your version of Django by using the version switcher at the bottom right corner of this page, or update Django to the newest version. If you’re using an older version of Python, check What Python version can I use with Django? to find a compatible version of Django.',\n",
       "  'url': 'https://docs.djangoproject.com/en/4.2/intro/tutorial01/'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20368"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon.index('django')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158507"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
